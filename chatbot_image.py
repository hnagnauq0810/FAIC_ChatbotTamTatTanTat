import base64
from io import BytesIO
from PIL import Image
from fetch_data_events import df
from faiss_index_events import load_faiss_db
from embedding import get_embedding
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
import os

def decode_base64_image(image_base64):
    if image_base64:
        image_data = base64.b64decode(image_base64)
        image = Image.open(BytesIO(image_data))
        return image
    return None

def search_faiss(query, top_k=15):
    """T√¨m ki·∫øm d·ªØ li·ªáu trong FAISS v√† tr·∫£ v·ªÅ danh s√°ch h√¨nh ·∫£nh & m√¥ t·∫£"""
    query_embedding = get_embedding(query).astype("float32").reshape(1, -1)
    D, I = faiss_index.search(query_embedding, top_k)

    descriptions = []
    image_list = []

    for idx in I[0]:
        if idx == -1:
            continue
        matched_data = docs[idx]
        metadata = matched_data["metadata"]
        
        # Gi·∫£i m√£ h√¨nh ·∫£nh t·ª´ Base64
        image = decode_base64_image(metadata.get("image_base64"))

        descriptions.append(f"üìå {metadata['name']} - {metadata['description']}")
        if image:
            image_list.append(image)

    if not descriptions:
        return "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p.", []

    return "\n\n".join(descriptions), image_list

faiss_index, docs = load_faiss_db()
llm = ChatOpenAI(api_key = "", model_name="gpt-4o-mini")

prompt_template = PromptTemplate(
    input_variables=["context", "question"],
    template="""
    B·∫°n l√† m·ªôt chatbot AI th√¥ng minh. D∆∞·ªõi ƒë√¢y l√† d·ªØ li·ªáu v·ªÅ s·ª± ki·ªán c√≥ li√™n quan:

    {context}

    Ng∆∞·ªùi d√πng h·ªèi: "{question}"
    
    H√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch chi ti·∫øt v√† d·ªÖ hi·ªÉu.
    """
)

def generate_openai_response(user_input, context):
    """G·ªçi OpenAI API ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu FAISS"""
    prompt = prompt_template.format(context=context, question=user_input)
    response = llm.predict(prompt)
    return response

def chatbot_interface(user_input):
    """H√†m ch√≠nh c·ªßa chatbot"""
    context, images = search_faiss(user_input)
    
    if context == "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p.":
        return images, "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p."

    response = generate_openai_response(user_input, context)
    return response, images
